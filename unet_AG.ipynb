{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Train: 6300, Val: 1350, Test: 1350\n",
      "Epoch [1/60] Train Loss: 0.004489, Val Loss: 0.000143\n",
      "  ✅ Saved Best Model at Epoch 1\n",
      "Epoch [2/60] Train Loss: 0.000099, Val Loss: 0.000063\n",
      "  ✅ Saved Best Model at Epoch 2\n",
      "Epoch [3/60] Train Loss: 0.000060, Val Loss: 0.000048\n",
      "  ✅ Saved Best Model at Epoch 3\n",
      "Epoch [4/60] Train Loss: 0.000039, Val Loss: 0.000041\n",
      "  ✅ Saved Best Model at Epoch 4\n",
      "Epoch [5/60] Train Loss: 0.000036, Val Loss: 0.000035\n",
      "  ✅ Saved Best Model at Epoch 5\n",
      "Epoch [6/60] Train Loss: 0.000031, Val Loss: 0.000053\n",
      "Epoch [7/60] Train Loss: 0.000027, Val Loss: 0.000037\n",
      "Epoch [8/60] Train Loss: 0.000031, Val Loss: 0.000021\n",
      "  ✅ Saved Best Model at Epoch 8\n",
      "Epoch [9/60] Train Loss: 0.000023, Val Loss: 0.000018\n",
      "  ✅ Saved Best Model at Epoch 9\n",
      "Epoch [10/60] Train Loss: 0.000022, Val Loss: 0.000031\n",
      "Epoch [11/60] Train Loss: 0.000024, Val Loss: 0.000017\n",
      "  ✅ Saved Best Model at Epoch 11\n",
      "Epoch [12/60] Train Loss: 0.000021, Val Loss: 0.000030\n",
      "Epoch [13/60] Train Loss: 0.000021, Val Loss: 0.000015\n",
      "  ✅ Saved Best Model at Epoch 13\n",
      "Epoch [14/60] Train Loss: 0.000020, Val Loss: 0.000020\n",
      "Epoch [15/60] Train Loss: 0.000020, Val Loss: 0.000015\n",
      "Epoch [16/60] Train Loss: 0.000019, Val Loss: 0.000024\n",
      "Epoch [17/60] Train Loss: 0.000017, Val Loss: 0.000030\n",
      "Epoch [18/60] Train Loss: 0.000018, Val Loss: 0.000018\n",
      "Epoch [19/60] Train Loss: 0.000016, Val Loss: 0.000014\n",
      "  ✅ Saved Best Model at Epoch 19\n",
      "Epoch [20/60] Train Loss: 0.000018, Val Loss: 0.000015\n",
      "Epoch [21/60] Train Loss: 0.000015, Val Loss: 0.000014\n",
      "Epoch [22/60] Train Loss: 0.000015, Val Loss: 0.000013\n",
      "  ✅ Saved Best Model at Epoch 22\n",
      "Epoch [23/60] Train Loss: 0.000015, Val Loss: 0.000013\n",
      "Epoch [24/60] Train Loss: 0.000022, Val Loss: 0.000014\n",
      "Epoch [25/60] Train Loss: 0.000014, Val Loss: 0.000011\n",
      "  ✅ Saved Best Model at Epoch 25\n",
      "Epoch [26/60] Train Loss: 0.000014, Val Loss: 0.000022\n",
      "Epoch [27/60] Train Loss: 0.000014, Val Loss: 0.000019\n",
      "Epoch [28/60] Train Loss: 0.000013, Val Loss: 0.000012\n",
      "Epoch [29/60] Train Loss: 0.000014, Val Loss: 0.000011\n",
      "  ✅ Saved Best Model at Epoch 29\n",
      "Epoch [30/60] Train Loss: 0.000012, Val Loss: 0.000012\n",
      "Epoch [31/60] Train Loss: 0.000011, Val Loss: 0.000011\n",
      "Epoch [32/60] Train Loss: 0.000012, Val Loss: 0.000010\n",
      "  ✅ Saved Best Model at Epoch 32\n",
      "Epoch [33/60] Train Loss: 0.000011, Val Loss: 0.000010\n",
      "  ✅ Saved Best Model at Epoch 33\n",
      "Epoch [34/60] Train Loss: 0.000011, Val Loss: 0.000009\n",
      "  ✅ Saved Best Model at Epoch 34\n",
      "Epoch [35/60] Train Loss: 0.000011, Val Loss: 0.000011\n",
      "Epoch [36/60] Train Loss: 0.000010, Val Loss: 0.000010\n",
      "Epoch [37/60] Train Loss: 0.000011, Val Loss: 0.000009\n",
      "  ✅ Saved Best Model at Epoch 37\n",
      "Epoch [38/60] Train Loss: 0.000010, Val Loss: 0.000010\n",
      "Epoch [39/60] Train Loss: 0.000009, Val Loss: 0.000010\n",
      "Epoch [40/60] Train Loss: 0.000009, Val Loss: 0.000009\n",
      "  ✅ Saved Best Model at Epoch 40\n",
      "Epoch [41/60] Train Loss: 0.000009, Val Loss: 0.000008\n",
      "  ✅ Saved Best Model at Epoch 41\n",
      "Epoch [42/60] Train Loss: 0.000009, Val Loss: 0.000007\n",
      "  ✅ Saved Best Model at Epoch 42\n",
      "Epoch [43/60] Train Loss: 0.000009, Val Loss: 0.000009\n",
      "Epoch [44/60] Train Loss: 0.000008, Val Loss: 0.000008\n",
      "Epoch [45/60] Train Loss: 0.000010, Val Loss: 0.000013\n",
      "Epoch [46/60] Train Loss: 0.000009, Val Loss: 0.000008\n",
      "Epoch [47/60] Train Loss: 0.000008, Val Loss: 0.000009\n",
      "Epoch [48/60] Train Loss: 0.000008, Val Loss: 0.000009\n",
      "Epoch [49/60] Train Loss: 0.000007, Val Loss: 0.000008\n",
      "Epoch [50/60] Train Loss: 0.000008, Val Loss: 0.000009\n",
      "Epoch [51/60] Train Loss: 0.000007, Val Loss: 0.000008\n",
      "Epoch [52/60] Train Loss: 0.000007, Val Loss: 0.000013\n",
      "Epoch [53/60] Train Loss: 0.000007, Val Loss: 0.000007\n",
      "Epoch [54/60] Train Loss: 0.000007, Val Loss: 0.000008\n",
      "Epoch [55/60] Train Loss: 0.000007, Val Loss: 0.000008\n",
      "Epoch [56/60] Train Loss: 0.000007, Val Loss: 0.000007\n",
      "Epoch [57/60] Train Loss: 0.000007, Val Loss: 0.000008\n",
      "Epoch [58/60] Train Loss: 0.000006, Val Loss: 0.000007\n",
      "  ✅ Saved Best Model at Epoch 58\n",
      "Epoch [59/60] Train Loss: 0.000007, Val Loss: 0.000006\n",
      "  ✅ Saved Best Model at Epoch 59\n",
      "Epoch [60/60] Train Loss: 0.000006, Val Loss: 0.000007\n",
      "\n",
      "Running inference on test set...\n",
      "Predictions saved in C:\\Preet\\9000_paired_bscans\\predictions_unet3_simpleAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "DATASET_DIR = r\"C:\\Preet\\9000_paired_bscans\"  # both *_l.png and *_h.png are here\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 60\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# DATASET\n",
    "# ==========================\n",
    "class GPRDataset(Dataset):\n",
    "    def __init__(self, x_paths, y_paths):\n",
    "        self.x_paths = x_paths\n",
    "        self.y_paths = y_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array(Image.open(self.x_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        y = np.array(Image.open(self.y_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        x = torch.tensor(x).unsqueeze(0)  # (1,H,W)\n",
    "        y = torch.tensor(y).unsqueeze(0)\n",
    "        return x, y\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    low_paths, high_paths = [], []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\"_l.png\"):\n",
    "            low_path = os.path.join(dataset_dir, file)\n",
    "            high_path = os.path.join(dataset_dir, file.replace(\"_l.png\", \"_h.png\"))\n",
    "            if os.path.exists(high_path):\n",
    "                low_paths.append(low_path)\n",
    "                high_paths.append(high_path)\n",
    "    return low_paths, high_paths\n",
    "\n",
    "all_x, all_y = load_data(DATASET_DIR)\n",
    "\n",
    "# Split 70/15/15\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(all_x, all_y, test_size=0.30, random_state=42)\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_x)}, Val: {len(val_x)}, Test: {len(test_x)}\")\n",
    "\n",
    "train_loader = DataLoader(GPRDataset(train_x, train_y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(GPRDataset(val_x, val_y), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(GPRDataset(test_x, test_y), batch_size=1, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# MODEL BLOCKS\n",
    "# ==========================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# TRAINING\n",
    "# ==========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "MODEL_PATH = os.path.join(DATASET_DIR, \"best_unet3_simpleAG.pth\")\n",
    "RESULTS_DIR = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "criterion = nn.HuberLoss(delta=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)   ##### change\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            preds = model(x)\n",
    "            val_loss += criterion(preds, y).item() * x.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"  ✅ Saved Best Model at Epoch {epoch+1}\")\n",
    "\n",
    "# ==========================\n",
    "# INFERENCE\n",
    "# ==========================\n",
    "print(\"\\nRunning inference on test set...\")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).cpu().squeeze(0).squeeze(0).numpy()\n",
    "    pred_img = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    Image.fromarray(pred_img).save(os.path.join(RESULTS_DIR, f\"pred_{i+1}.png\"))\n",
    "\n",
    "print(f\"Predictions saved in {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c96965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set Evaluation ----\n",
      "SSIM: avg=0.8936, min=0.7132, max=0.9973\n",
      "PSNR: avg=35.44 dB, min=28.49 dB, max=51.78 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "import shutil\n",
    "\n",
    "# ==== COPY GT FILES ====\n",
    "os.makedirs(r\"C:\\Preet\\9000_paired_bscans\\ground_truth_test_unet3_simpleAG\", exist_ok=True)\n",
    "\n",
    "for f in test_y:  # list of test high-res paths from your train/val/test split\n",
    "    shutil.copy(f, r\"C:\\Preet\\9000_paired_bscans\\ground_truth_test_unet3_simpleAG\")\n",
    "\n",
    "# ==== PATHS ====\n",
    "pred_dir = r\"C:\\Preet\\9000_paired_bscans\\predictions_unet3_simpleAG\"\n",
    "gt_dir   = r\"C:\\Preet\\9000_paired_bscans\\ground_truth_test_unet3_simpleAG\"\n",
    "\n",
    "\n",
    "# ==== FUNCTIONS ====\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "# ==== MAIN ====\n",
    "psnr_values, ssim_values = [], []\n",
    "\n",
    "pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "gt_files   = sorted([f for f in os.listdir(gt_dir)   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "num_pairs = min(len(pred_files), len(gt_files))\n",
    "if num_pairs == 0:\n",
    "    print(\"[Error] No matching image files found in both directories.\")\n",
    "else:\n",
    "    if len(pred_files) != len(gt_files):\n",
    "        print(f\"[Warning] Different number of images: Predictions={len(pred_files)}, Ground Truth={len(gt_files)}\")\n",
    "        print(f\"Evaluating only first {num_pairs} matched pairs.\")\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        pred_path = os.path.join(pred_dir, pred_files[i])\n",
    "        gt_path   = os.path.join(gt_dir, gt_files[i])\n",
    "\n",
    "        pred_img = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt_img   = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if pred_img is None or gt_img is None:\n",
    "            print(f\"[Error] Could not load: {pred_files[i]} or {gt_files[i]}\")\n",
    "            continue\n",
    "\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"\\n---- Test Set Evaluation ----\")\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e797e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Evaluating png_images_650M_1083M ----\n",
      "SSIM: avg=0.9590, min=0.9304, max=0.9720\n",
      "PSNR: avg=35.82 dB, min=31.96 dB, max=37.05 dB\n",
      "\n",
      "---- Evaluating png_images_700M_1167M ----\n",
      "SSIM: avg=0.9831, min=0.7585, max=0.9883\n",
      "PSNR: avg=36.33 dB, min=29.18 dB, max=37.12 dB\n",
      "\n",
      "---- Evaluating png_images_800M_1333M ----\n",
      "SSIM: avg=0.9893, min=0.9698, max=0.9932\n",
      "PSNR: avg=39.12 dB, min=33.66 dB, max=40.17 dB\n",
      "\n",
      "---- Evaluating png_images_850M_1416M ----\n",
      "SSIM: avg=0.9646, min=0.9317, max=0.9755\n",
      "PSNR: avg=36.27 dB, min=31.68 dB, max=37.76 dB\n",
      "\n",
      "---- Evaluating png_images_900M_1500M ----\n",
      "SSIM: avg=0.9247, min=0.8795, max=0.9439\n",
      "PSNR: avg=32.90 dB, min=29.71 dB, max=33.86 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "FREQ_DIRS = [\n",
    "    r\"C:\\Preet\\validation dataset\\png_images_650M_1083M\",\n",
    "    r\"C:\\Preet\\validation dataset\\png_images_700M_1167M\",\n",
    "    r\"C:\\Preet\\validation dataset\\png_images_800M_1333M\",\n",
    "    r\"C:\\Preet\\validation dataset\\png_images_850M_1416M\",\n",
    "    r\"C:\\Preet\\validation dataset\\png_images_900M_1500M\",\n",
    "]\n",
    "\n",
    "MODEL_PATH = r\"C:\\Preet\\9000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "# =========================\n",
    "# LOAD SIMPLE UNET MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# INFERENCE LOOP\n",
    "# =========================\n",
    "for freq_dir in FREQ_DIRS:\n",
    "    print(f\"\\n---- Evaluating {os.path.basename(freq_dir)} ----\")\n",
    "    pred_dir = os.path.join(freq_dir, \"predictions_unet3_simpleAG\")\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "    low_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_l.png\")])\n",
    "    high_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_h.png\")])\n",
    "\n",
    "    psnr_values, ssim_values = [], []\n",
    "\n",
    "    for i in range(len(low_files)):\n",
    "        low_path = os.path.join(freq_dir, low_files[i])\n",
    "        high_path = os.path.join(freq_dir, high_files[i])\n",
    "\n",
    "        # Load LR\n",
    "        lr_img = np.array(Image.open(low_path).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        lr_tensor = torch.tensor(lr_img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            pred = model(lr_tensor).cpu().numpy()\n",
    "\n",
    "        # remove batch and channel dims, scale to 0-255\n",
    "        pred_img = np.squeeze(pred)\n",
    "        pred_img = (pred_img * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        # increase contrast (normalize like GT)\n",
    "        pred_img = cv2.normalize(pred_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # save prediction\n",
    "        pred_path = os.path.join(pred_dir, f\"pred_{i+1}.png\")\n",
    "        Image.fromarray(pred_img).save(pred_path)\n",
    "\n",
    "        # Load GT\n",
    "        gt_img = cv2.imread(high_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        # Metrics\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    # Results\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n",
    "    else:\n",
    "        print(\"[Error] No valid pairs processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9c292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 650 → pred → compare with 1083 ----\n",
      "SSIM: avg=0.9567, min=0.9298, max=0.9713\n",
      "PSNR: avg=35.64 dB, min=32.20 dB, max=36.93 dB\n",
      "\n",
      "---- Stage 2: pred_1083 → pred → compare with 1800 ----\n",
      "SSIM: avg=0.9210, min=0.8751, max=0.9431\n",
      "PSNR: avg=30.36 dB, min=29.37 dB, max=30.97 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\validation dataset\\png_images_650M_1083M_1800M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\9000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"650_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1083_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1800_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 650 → pred → compare with 1083 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1083 → pred → compare with 1800 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4935da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 900 → pred → compare with 1500 ----\n",
      "SSIM: avg=0.7274, min=0.5844, max=0.8595\n",
      "PSNR: avg=30.06 dB, min=29.24 dB, max=30.89 dB\n",
      "\n",
      "---- Stage 2: pred_1500 → pred → compare with 2500 ----\n",
      "SSIM: avg=0.7336, min=0.6345, max=0.8428\n",
      "PSNR: avg=26.99 dB, min=26.50 dB, max=27.69 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\validation dataset\\png_images_900M_1500M_2500M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\9000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"900_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1500_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"2500_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 900 → pred → compare with 1500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1500 → pred → compare with 2500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f606f5",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123716d",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11facac5",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d63895",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a9609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Train: 2800, Val: 600, Test: 600\n",
      "Epoch [1/60] Train Loss: 0.009756, Val Loss: 0.000264\n",
      "  ✅ Saved Best Model at Epoch 1\n",
      "Epoch [2/60] Train Loss: 0.000183, Val Loss: 0.000131\n",
      "  ✅ Saved Best Model at Epoch 2\n",
      "Epoch [3/60] Train Loss: 0.000108, Val Loss: 0.000091\n",
      "  ✅ Saved Best Model at Epoch 3\n",
      "Epoch [4/60] Train Loss: 0.000070, Val Loss: 0.000058\n",
      "  ✅ Saved Best Model at Epoch 4\n",
      "Epoch [5/60] Train Loss: 0.000064, Val Loss: 0.000042\n",
      "  ✅ Saved Best Model at Epoch 5\n",
      "Epoch [6/60] Train Loss: 0.000046, Val Loss: 0.000040\n",
      "  ✅ Saved Best Model at Epoch 6\n",
      "Epoch [7/60] Train Loss: 0.000042, Val Loss: 0.000042\n",
      "Epoch [8/60] Train Loss: 0.000035, Val Loss: 0.000036\n",
      "  ✅ Saved Best Model at Epoch 8\n",
      "Epoch [9/60] Train Loss: 0.000038, Val Loss: 0.000029\n",
      "  ✅ Saved Best Model at Epoch 9\n",
      "Epoch [10/60] Train Loss: 0.000031, Val Loss: 0.000039\n",
      "Epoch [11/60] Train Loss: 0.000030, Val Loss: 0.000025\n",
      "  ✅ Saved Best Model at Epoch 11\n",
      "Epoch [12/60] Train Loss: 0.000030, Val Loss: 0.000024\n",
      "  ✅ Saved Best Model at Epoch 12\n",
      "Epoch [13/60] Train Loss: 0.000028, Val Loss: 0.000022\n",
      "  ✅ Saved Best Model at Epoch 13\n",
      "Epoch [14/60] Train Loss: 0.000028, Val Loss: 0.000022\n",
      "  ✅ Saved Best Model at Epoch 14\n",
      "Epoch [15/60] Train Loss: 0.000025, Val Loss: 0.000024\n",
      "Epoch [16/60] Train Loss: 0.000097, Val Loss: 0.000915\n",
      "Epoch [17/60] Train Loss: 0.000078, Val Loss: 0.000023\n",
      "Epoch [18/60] Train Loss: 0.000023, Val Loss: 0.000021\n",
      "  ✅ Saved Best Model at Epoch 18\n",
      "Epoch [19/60] Train Loss: 0.000021, Val Loss: 0.000021\n",
      "Epoch [20/60] Train Loss: 0.000021, Val Loss: 0.000022\n",
      "Epoch [21/60] Train Loss: 0.000020, Val Loss: 0.000021\n",
      "Epoch [22/60] Train Loss: 0.000020, Val Loss: 0.000017\n",
      "  ✅ Saved Best Model at Epoch 22\n",
      "Epoch [23/60] Train Loss: 0.000019, Val Loss: 0.000017\n",
      "Epoch [24/60] Train Loss: 0.000019, Val Loss: 0.000017\n",
      "  ✅ Saved Best Model at Epoch 24\n",
      "Epoch [25/60] Train Loss: 0.000018, Val Loss: 0.000022\n",
      "Epoch [26/60] Train Loss: 0.000018, Val Loss: 0.000017\n",
      "Epoch [27/60] Train Loss: 0.000020, Val Loss: 0.000018\n",
      "Epoch [28/60] Train Loss: 0.000021, Val Loss: 0.000018\n",
      "Epoch [29/60] Train Loss: 0.000020, Val Loss: 0.000015\n",
      "  ✅ Saved Best Model at Epoch 29\n",
      "Epoch [30/60] Train Loss: 0.000019, Val Loss: 0.000026\n",
      "Epoch [31/60] Train Loss: 0.000020, Val Loss: 0.000020\n",
      "Epoch [32/60] Train Loss: 0.000017, Val Loss: 0.000017\n",
      "Epoch [33/60] Train Loss: 0.000019, Val Loss: 0.000013\n",
      "  ✅ Saved Best Model at Epoch 33\n",
      "Epoch [34/60] Train Loss: 0.000023, Val Loss: 0.000018\n",
      "Epoch [35/60] Train Loss: 0.000019, Val Loss: 0.000017\n",
      "Epoch [36/60] Train Loss: 0.000016, Val Loss: 0.000018\n",
      "Epoch [37/60] Train Loss: 0.000016, Val Loss: 0.000016\n",
      "Epoch [38/60] Train Loss: 0.000018, Val Loss: 0.000017\n",
      "Epoch [39/60] Train Loss: 0.000018, Val Loss: 0.000014\n",
      "Epoch [40/60] Train Loss: 0.000016, Val Loss: 0.000014\n",
      "Epoch [41/60] Train Loss: 0.000016, Val Loss: 0.000012\n",
      "  ✅ Saved Best Model at Epoch 41\n",
      "Epoch [42/60] Train Loss: 0.000018, Val Loss: 0.000021\n",
      "Epoch [43/60] Train Loss: 0.000016, Val Loss: 0.000013\n",
      "Epoch [44/60] Train Loss: 0.000015, Val Loss: 0.000014\n",
      "Epoch [45/60] Train Loss: 0.000014, Val Loss: 0.000013\n",
      "Epoch [46/60] Train Loss: 0.000015, Val Loss: 0.000017\n",
      "Epoch [47/60] Train Loss: 0.000016, Val Loss: 0.000022\n",
      "Epoch [48/60] Train Loss: 0.000015, Val Loss: 0.000011\n",
      "  ✅ Saved Best Model at Epoch 48\n",
      "Epoch [49/60] Train Loss: 0.000014, Val Loss: 0.000012\n",
      "Epoch [50/60] Train Loss: 0.000014, Val Loss: 0.000012\n",
      "Epoch [51/60] Train Loss: 0.000014, Val Loss: 0.000013\n",
      "Epoch [52/60] Train Loss: 0.000016, Val Loss: 0.000020\n",
      "Epoch [53/60] Train Loss: 0.000015, Val Loss: 0.000010\n",
      "  ✅ Saved Best Model at Epoch 53\n",
      "Epoch [54/60] Train Loss: 0.000013, Val Loss: 0.000011\n",
      "Epoch [55/60] Train Loss: 0.000013, Val Loss: 0.000012\n",
      "Epoch [56/60] Train Loss: 0.000013, Val Loss: 0.000014\n",
      "Epoch [57/60] Train Loss: 0.000013, Val Loss: 0.000012\n",
      "Epoch [58/60] Train Loss: 0.000012, Val Loss: 0.000010\n",
      "  ✅ Saved Best Model at Epoch 58\n",
      "Epoch [59/60] Train Loss: 0.000015, Val Loss: 0.000018\n",
      "Epoch [60/60] Train Loss: 0.000013, Val Loss: 0.000011\n",
      "\n",
      "Running inference on test set...\n",
      "Predictions saved in C:\\Preet\\4000_paired_bscans\\predictions_unet3_simpleAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "DATASET_DIR = r\"C:\\Preet\\4000_paired_bscans\"  # both *_l.png and *_h.png are here\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 60\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# DATASET\n",
    "# ==========================\n",
    "class GPRDataset(Dataset):\n",
    "    def __init__(self, x_paths, y_paths):\n",
    "        self.x_paths = x_paths\n",
    "        self.y_paths = y_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array(Image.open(self.x_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        y = np.array(Image.open(self.y_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        x = torch.tensor(x).unsqueeze(0)  # (1,H,W)\n",
    "        y = torch.tensor(y).unsqueeze(0)\n",
    "        return x, y\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    low_paths, high_paths = [], []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\"_l.png\"):\n",
    "            low_path = os.path.join(dataset_dir, file)\n",
    "            high_path = os.path.join(dataset_dir, file.replace(\"_l.png\", \"_h.png\"))\n",
    "            if os.path.exists(high_path):\n",
    "                low_paths.append(low_path)\n",
    "                high_paths.append(high_path)\n",
    "    return low_paths, high_paths\n",
    "\n",
    "all_x, all_y = load_data(DATASET_DIR)\n",
    "\n",
    "# Split 70/15/15\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(all_x, all_y, test_size=0.30, random_state=42)\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_x)}, Val: {len(val_x)}, Test: {len(test_x)}\")\n",
    "\n",
    "train_loader = DataLoader(GPRDataset(train_x, train_y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(GPRDataset(val_x, val_y), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(GPRDataset(test_x, test_y), batch_size=1, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# MODEL BLOCKS\n",
    "# ==========================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# TRAINING\n",
    "# ==========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "MODEL_PATH = os.path.join(DATASET_DIR, \"best_unet3_simpleAG.pth\")\n",
    "RESULTS_DIR = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "criterion = nn.HuberLoss(delta=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)   ##### change\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            preds = model(x)\n",
    "            val_loss += criterion(preds, y).item() * x.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"  ✅ Saved Best Model at Epoch {epoch+1}\")\n",
    "\n",
    "# ==========================\n",
    "# INFERENCE\n",
    "# ==========================\n",
    "print(\"\\nRunning inference on test set...\")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).cpu().squeeze(0).squeeze(0).numpy()\n",
    "    pred_img = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    Image.fromarray(pred_img).save(os.path.join(RESULTS_DIR, f\"pred_{i+1}.png\"))\n",
    "\n",
    "print(f\"Predictions saved in {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355141c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set Evaluation ----\n",
      "SSIM: avg=0.8921, min=0.7142, max=0.9977\n",
      "PSNR: avg=35.31 dB, min=28.98 dB, max=48.85 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "import shutil\n",
    "\n",
    "# ==== COPY GT FILES ====\n",
    "os.makedirs(r\"C:\\Preet\\4000_paired_bscans\\ground_truth_test_unet3_simpleAG\", exist_ok=True)\n",
    "\n",
    "for f in test_y:  # list of test high-res paths from your train/val/test split\n",
    "    shutil.copy(f, r\"C:\\Preet\\4000_paired_bscans\\ground_truth_test_unet3_simpleAG\")\n",
    "\n",
    "# ==== PATHS ====\n",
    "pred_dir = r\"C:\\Preet\\4000_paired_bscans\\predictions_unet3_simpleAG\"\n",
    "gt_dir   = r\"C:\\Preet\\4000_paired_bscans\\ground_truth_test_unet3_simpleAG\"\n",
    "\n",
    "\n",
    "# ==== FUNCTIONS ====\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "# ==== MAIN ====\n",
    "psnr_values, ssim_values = [], []\n",
    "\n",
    "pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "gt_files   = sorted([f for f in os.listdir(gt_dir)   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "num_pairs = min(len(pred_files), len(gt_files))\n",
    "if num_pairs == 0:\n",
    "    print(\"[Error] No matching image files found in both directories.\")\n",
    "else:\n",
    "    if len(pred_files) != len(gt_files):\n",
    "        print(f\"[Warning] Different number of images: Predictions={len(pred_files)}, Ground Truth={len(gt_files)}\")\n",
    "        print(f\"Evaluating only first {num_pairs} matched pairs.\")\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        pred_path = os.path.join(pred_dir, pred_files[i])\n",
    "        gt_path   = os.path.join(gt_dir, gt_files[i])\n",
    "\n",
    "        pred_img = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt_img   = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if pred_img is None or gt_img is None:\n",
    "            print(f\"[Error] Could not load: {pred_files[i]} or {gt_files[i]}\")\n",
    "            continue\n",
    "\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"\\n---- Test Set Evaluation ----\")\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52b5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Evaluating png_images_650M_1083M ----\n",
      "SSIM: avg=0.9608, min=0.9238, max=0.9749\n",
      "PSNR: avg=35.53 dB, min=31.44 dB, max=37.12 dB\n",
      "\n",
      "---- Evaluating png_images_700M_1167M ----\n",
      "SSIM: avg=0.9833, min=0.7490, max=0.9896\n",
      "PSNR: avg=38.77 dB, min=29.14 dB, max=40.24 dB\n",
      "\n",
      "---- Evaluating png_images_800M_1333M ----\n",
      "SSIM: avg=0.9884, min=0.9603, max=0.9927\n",
      "PSNR: avg=37.63 dB, min=32.84 dB, max=39.08 dB\n",
      "\n",
      "---- Evaluating png_images_850M_1416M ----\n",
      "SSIM: avg=0.9662, min=0.9213, max=0.9771\n",
      "PSNR: avg=33.73 dB, min=30.55 dB, max=34.67 dB\n",
      "\n",
      "---- Evaluating png_images_900M_1500M ----\n",
      "SSIM: avg=0.9300, min=0.8690, max=0.9488\n",
      "PSNR: avg=33.40 dB, min=30.16 dB, max=34.29 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "FREQ_DIRS = [\n",
    "    r\"C:\\Preet\\validation dataset_4000\\png_images_650M_1083M\",\n",
    "    r\"C:\\Preet\\validation dataset_4000\\png_images_700M_1167M\",\n",
    "    r\"C:\\Preet\\validation dataset_4000\\png_images_800M_1333M\",\n",
    "    r\"C:\\Preet\\validation dataset_4000\\png_images_850M_1416M\",\n",
    "    r\"C:\\Preet\\validation dataset_4000\\png_images_900M_1500M\",\n",
    "]\n",
    "\n",
    "MODEL_PATH = r\"C:\\Preet\\4000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "# =========================\n",
    "# LOAD SIMPLE UNET MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# INFERENCE LOOP\n",
    "# =========================\n",
    "for freq_dir in FREQ_DIRS:\n",
    "    print(f\"\\n---- Evaluating {os.path.basename(freq_dir)} ----\")\n",
    "    pred_dir = os.path.join(freq_dir, \"predictions_unet3_simpleAG\")\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "    low_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_l.png\")])\n",
    "    high_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_h.png\")])\n",
    "\n",
    "    psnr_values, ssim_values = [], []\n",
    "\n",
    "    for i in range(len(low_files)):\n",
    "        low_path = os.path.join(freq_dir, low_files[i])\n",
    "        high_path = os.path.join(freq_dir, high_files[i])\n",
    "\n",
    "        # Load LR\n",
    "        lr_img = np.array(Image.open(low_path).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        lr_tensor = torch.tensor(lr_img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            pred = model(lr_tensor).cpu().numpy()\n",
    "\n",
    "        # remove batch and channel dims, scale to 0-255\n",
    "        pred_img = np.squeeze(pred)\n",
    "        pred_img = (pred_img * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        # increase contrast (normalize like GT)\n",
    "        pred_img = cv2.normalize(pred_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # save prediction\n",
    "        pred_path = os.path.join(pred_dir, f\"pred_{i+1}.png\")\n",
    "        Image.fromarray(pred_img).save(pred_path)\n",
    "\n",
    "        # Load GT\n",
    "        gt_img = cv2.imread(high_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        # Metrics\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    # Results\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n",
    "    else:\n",
    "        print(\"[Error] No valid pairs processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b116fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 650 → pred → compare with 1083 ----\n",
      "SSIM: avg=0.9584, min=0.9271, max=0.9740\n",
      "PSNR: avg=35.34 dB, min=31.96 dB, max=36.74 dB\n",
      "\n",
      "---- Stage 2: pred_1083 → pred → compare with 1800 ----\n",
      "SSIM: avg=0.8939, min=0.8489, max=0.9155\n",
      "PSNR: avg=30.37 dB, min=28.46 dB, max=31.86 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\validation dataset_4000\\png_images_650M_1083M_1800M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\4000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"650_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1083_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1800_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 650 → pred → compare with 1083 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1083 → pred → compare with 1800 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472baf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 900 → pred → compare with 1500 ----\n",
      "SSIM: avg=0.7532, min=0.6154, max=0.8841\n",
      "PSNR: avg=30.28 dB, min=29.08 dB, max=30.88 dB\n",
      "\n",
      "---- Stage 2: pred_1500 → pred → compare with 2500 ----\n",
      "SSIM: avg=0.7729, min=0.6915, max=0.8629\n",
      "PSNR: avg=26.34 dB, min=25.81 dB, max=27.15 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\validation dataset_4000\\png_images_900M_1500M_2500M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\4000_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"900_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1500_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"2500_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 900 → pred → compare with 1500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1500 → pred → compare with 2500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe91a62",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c67dc",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734ea4e",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5abed",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718774c",
   "metadata": {},
   "source": [
    "clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76d78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Train: 5810, Val: 1245, Test: 1245\n",
      "Epoch [1/60] Train Loss: 0.003713, Val Loss: 0.000101\n",
      "  ✅ Saved Best Model at Epoch 1\n",
      "Epoch [2/60] Train Loss: 0.000058, Val Loss: 0.000057\n",
      "  ✅ Saved Best Model at Epoch 2\n",
      "Epoch [3/60] Train Loss: 0.000029, Val Loss: 0.000032\n",
      "  ✅ Saved Best Model at Epoch 3\n",
      "Epoch [4/60] Train Loss: 0.000022, Val Loss: 0.000031\n",
      "  ✅ Saved Best Model at Epoch 4\n",
      "Epoch [5/60] Train Loss: 0.000017, Val Loss: 0.000012\n",
      "  ✅ Saved Best Model at Epoch 5\n",
      "Epoch [6/60] Train Loss: 0.000015, Val Loss: 0.000045\n",
      "Epoch [7/60] Train Loss: 0.000014, Val Loss: 0.000010\n",
      "  ✅ Saved Best Model at Epoch 7\n",
      "Epoch [8/60] Train Loss: 0.000013, Val Loss: 0.000009\n",
      "  ✅ Saved Best Model at Epoch 8\n",
      "Epoch [9/60] Train Loss: 0.000012, Val Loss: 0.000021\n",
      "Epoch [10/60] Train Loss: 0.000011, Val Loss: 0.000010\n",
      "Epoch [11/60] Train Loss: 0.000010, Val Loss: 0.000022\n",
      "Epoch [12/60] Train Loss: 0.000010, Val Loss: 0.000007\n",
      "  ✅ Saved Best Model at Epoch 12\n",
      "Epoch [13/60] Train Loss: 0.000009, Val Loss: 0.000034\n",
      "Epoch [14/60] Train Loss: 0.000009, Val Loss: 0.000008\n",
      "Epoch [15/60] Train Loss: 0.000008, Val Loss: 0.000005\n",
      "  ✅ Saved Best Model at Epoch 15\n",
      "Epoch [16/60] Train Loss: 0.000007, Val Loss: 0.000004\n",
      "  ✅ Saved Best Model at Epoch 16\n",
      "Epoch [17/60] Train Loss: 0.000007, Val Loss: 0.000006\n",
      "Epoch [18/60] Train Loss: 0.000007, Val Loss: 0.000007\n",
      "Epoch [19/60] Train Loss: 0.000007, Val Loss: 0.000006\n",
      "Epoch [20/60] Train Loss: 0.000007, Val Loss: 0.000017\n",
      "Epoch [21/60] Train Loss: 0.000006, Val Loss: 0.000009\n",
      "Epoch [22/60] Train Loss: 0.000006, Val Loss: 0.000086\n",
      "Epoch [23/60] Train Loss: 0.000006, Val Loss: 0.000007\n",
      "Epoch [24/60] Train Loss: 0.000006, Val Loss: 0.000004\n",
      "  ✅ Saved Best Model at Epoch 24\n",
      "Epoch [25/60] Train Loss: 0.000005, Val Loss: 0.000004\n",
      "  ✅ Saved Best Model at Epoch 25\n",
      "Epoch [26/60] Train Loss: 0.000006, Val Loss: 0.000004\n",
      "  ✅ Saved Best Model at Epoch 26\n",
      "Epoch [27/60] Train Loss: 0.000005, Val Loss: 0.000005\n",
      "Epoch [28/60] Train Loss: 0.000005, Val Loss: 0.000003\n",
      "  ✅ Saved Best Model at Epoch 28\n",
      "Epoch [29/60] Train Loss: 0.000005, Val Loss: 0.000003\n",
      "Epoch [30/60] Train Loss: 0.000005, Val Loss: 0.000003\n",
      "Epoch [31/60] Train Loss: 0.000005, Val Loss: 0.000003\n",
      "Epoch [32/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "  ✅ Saved Best Model at Epoch 32\n",
      "Epoch [33/60] Train Loss: 0.000005, Val Loss: 0.000004\n",
      "Epoch [34/60] Train Loss: 0.000004, Val Loss: 0.000004\n",
      "Epoch [35/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "Epoch [36/60] Train Loss: 0.000005, Val Loss: 0.000004\n",
      "Epoch [37/60] Train Loss: 0.000004, Val Loss: 0.000004\n",
      "Epoch [38/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "Epoch [39/60] Train Loss: 0.000004, Val Loss: 0.000004\n",
      "Epoch [40/60] Train Loss: 0.000004, Val Loss: 0.000002\n",
      "  ✅ Saved Best Model at Epoch 40\n",
      "Epoch [41/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "Epoch [42/60] Train Loss: 0.000004, Val Loss: 0.000002\n",
      "  ✅ Saved Best Model at Epoch 42\n",
      "Epoch [43/60] Train Loss: 0.000004, Val Loss: 0.000002\n",
      "Epoch [44/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "Epoch [45/60] Train Loss: 0.000004, Val Loss: 0.000003\n",
      "Epoch [46/60] Train Loss: 0.000004, Val Loss: 0.000006\n",
      "Epoch [47/60] Train Loss: 0.000003, Val Loss: 0.000004\n",
      "Epoch [48/60] Train Loss: 0.000004, Val Loss: 0.000002\n",
      "Epoch [49/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [50/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [51/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [52/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [53/60] Train Loss: 0.000003, Val Loss: 0.000002\n",
      "  ✅ Saved Best Model at Epoch 53\n",
      "Epoch [54/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [55/60] Train Loss: 0.000003, Val Loss: 0.000002\n",
      "Epoch [56/60] Train Loss: 0.000003, Val Loss: 0.000003\n",
      "Epoch [57/60] Train Loss: 0.000003, Val Loss: 0.000005\n",
      "Epoch [58/60] Train Loss: 0.000003, Val Loss: 0.000004\n",
      "Epoch [59/60] Train Loss: 0.000003, Val Loss: 0.000005\n",
      "Epoch [60/60] Train Loss: 0.000003, Val Loss: 0.000002\n",
      "  ✅ Saved Best Model at Epoch 60\n",
      "\n",
      "Running inference on test set...\n",
      "Predictions saved in C:\\Preet\\clean_paired_bscans\\predictions_unet3_simpleAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# ==========================\n",
    "# CONFIG\n",
    "# ==========================\n",
    "DATASET_DIR = r\"C:\\Preet\\clean_paired_bscans\"  # both *_l.png and *_h.png are here\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 60\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# DATASET\n",
    "# ==========================\n",
    "class GPRDataset(Dataset):\n",
    "    def __init__(self, x_paths, y_paths):\n",
    "        self.x_paths = x_paths\n",
    "        self.y_paths = y_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array(Image.open(self.x_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        y = np.array(Image.open(self.y_paths[idx]).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        x = torch.tensor(x).unsqueeze(0)  # (1,H,W)\n",
    "        y = torch.tensor(y).unsqueeze(0)\n",
    "        return x, y\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    low_paths, high_paths = [], []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\"_l.png\"):\n",
    "            low_path = os.path.join(dataset_dir, file)\n",
    "            high_path = os.path.join(dataset_dir, file.replace(\"_l.png\", \"_h.png\"))\n",
    "            if os.path.exists(high_path):\n",
    "                low_paths.append(low_path)\n",
    "                high_paths.append(high_path)\n",
    "    return low_paths, high_paths\n",
    "\n",
    "all_x, all_y = load_data(DATASET_DIR)\n",
    "\n",
    "# Split 70/15/15\n",
    "train_x, temp_x, train_y, temp_y = train_test_split(all_x, all_y, test_size=0.30, random_state=42)\n",
    "val_x, test_x, val_y, test_y = train_test_split(temp_x, temp_y, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_x)}, Val: {len(val_x)}, Test: {len(test_x)}\")\n",
    "\n",
    "train_loader = DataLoader(GPRDataset(train_x, train_y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(GPRDataset(val_x, val_y), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(GPRDataset(test_x, test_y), batch_size=1, shuffle=False)\n",
    "\n",
    "# ==========================\n",
    "# MODEL BLOCKS\n",
    "# ==========================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# TRAINING\n",
    "# ==========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "MODEL_PATH = os.path.join(DATASET_DIR, \"best_unet3_simpleAG.pth\")\n",
    "RESULTS_DIR = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "criterion = nn.HuberLoss(delta=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)   ##### change\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            preds = model(x)\n",
    "            val_loss += criterion(preds, y).item() * x.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"  ✅ Saved Best Model at Epoch {epoch+1}\")\n",
    "\n",
    "# ==========================\n",
    "# INFERENCE\n",
    "# ==========================\n",
    "print(\"\\nRunning inference on test set...\")\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "for i, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).cpu().squeeze(0).squeeze(0).numpy()\n",
    "    pred_img = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    Image.fromarray(pred_img).save(os.path.join(RESULTS_DIR, f\"pred_{i+1}.png\"))\n",
    "\n",
    "print(f\"Predictions saved in {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5322f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Test Set Evaluation ----\n",
      "SSIM: avg=0.9044, min=0.7490, max=0.9978\n",
      "PSNR: avg=35.97 dB, min=28.83 dB, max=51.51 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "import shutil\n",
    "\n",
    "# ==== COPY GT FILES ====\n",
    "os.makedirs(r\"C:\\Preet\\clean_paired_bscans\\ground_truth_test_unet3_simpleAG\", exist_ok=True)\n",
    "\n",
    "for f in test_y:  # list of test high-res paths from your train/val/test split\n",
    "    shutil.copy(f, r\"C:\\Preet\\clean_paired_bscans\\ground_truth_test_unet3_simpleAG\")\n",
    "\n",
    "# ==== PATHS ====\n",
    "pred_dir = r\"C:\\Preet\\clean_paired_bscans\\predictions_unet3_simpleAG\"\n",
    "gt_dir   = r\"C:\\Preet\\clean_paired_bscans\\ground_truth_test_unet3_simpleAG\"\n",
    "\n",
    "\n",
    "# ==== FUNCTIONS ====\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "# ==== MAIN ====\n",
    "psnr_values, ssim_values = [], []\n",
    "\n",
    "pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "gt_files   = sorted([f for f in os.listdir(gt_dir)   if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "num_pairs = min(len(pred_files), len(gt_files))\n",
    "if num_pairs == 0:\n",
    "    print(\"[Error] No matching image files found in both directories.\")\n",
    "else:\n",
    "    if len(pred_files) != len(gt_files):\n",
    "        print(f\"[Warning] Different number of images: Predictions={len(pred_files)}, Ground Truth={len(gt_files)}\")\n",
    "        print(f\"Evaluating only first {num_pairs} matched pairs.\")\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        pred_path = os.path.join(pred_dir, pred_files[i])\n",
    "        gt_path   = os.path.join(gt_dir, gt_files[i])\n",
    "\n",
    "        pred_img = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "        gt_img   = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if pred_img is None or gt_img is None:\n",
    "            print(f\"[Error] Could not load: {pred_files[i]} or {gt_files[i]}\")\n",
    "            continue\n",
    "\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"\\n---- Test Set Evaluation ----\")\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6b91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Evaluating png_images_650M_1083M ----\n",
      "SSIM: avg=0.9566, min=0.9246, max=0.9676\n",
      "PSNR: avg=34.18 dB, min=32.13 dB, max=35.00 dB\n",
      "\n",
      "---- Evaluating png_images_700M_1167M ----\n",
      "SSIM: avg=0.9823, min=0.8242, max=0.9860\n",
      "PSNR: avg=35.34 dB, min=32.11 dB, max=35.91 dB\n",
      "\n",
      "---- Evaluating png_images_800M_1333M ----\n",
      "SSIM: avg=0.9891, min=0.9792, max=0.9925\n",
      "PSNR: avg=39.64 dB, min=35.48 dB, max=40.58 dB\n",
      "\n",
      "---- Evaluating png_images_850M_1416M ----\n",
      "SSIM: avg=0.9661, min=0.9381, max=0.9764\n",
      "PSNR: avg=35.31 dB, min=32.42 dB, max=36.65 dB\n",
      "\n",
      "---- Evaluating png_images_900M_1500M ----\n",
      "SSIM: avg=0.9282, min=0.8740, max=0.9458\n",
      "PSNR: avg=33.86 dB, min=31.06 dB, max=34.82 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "FREQ_DIRS = [\n",
    "    r\"C:\\Preet\\clean_validation dataset\\png_images_650M_1083M\",\n",
    "    r\"C:\\Preet\\clean_validation dataset\\png_images_700M_1167M\",\n",
    "    r\"C:\\Preet\\clean_validation dataset\\png_images_800M_1333M\",\n",
    "    r\"C:\\Preet\\clean_validation dataset\\png_images_850M_1416M\",\n",
    "    r\"C:\\Preet\\clean_validation dataset\\png_images_900M_1500M\",\n",
    "]\n",
    "\n",
    "MODEL_PATH = r\"C:\\Preet\\clean_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "# =========================\n",
    "# LOAD SIMPLE UNET MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# INFERENCE LOOP\n",
    "# =========================\n",
    "for freq_dir in FREQ_DIRS:\n",
    "    print(f\"\\n---- Evaluating {os.path.basename(freq_dir)} ----\")\n",
    "    pred_dir = os.path.join(freq_dir, \"predictions_unet3_simpleAG\")\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "    low_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_l.png\")])\n",
    "    high_files = numerical_sort([f for f in os.listdir(freq_dir) if f.endswith(\"_h.png\")])\n",
    "\n",
    "    psnr_values, ssim_values = [], []\n",
    "\n",
    "    for i in range(len(low_files)):\n",
    "        low_path = os.path.join(freq_dir, low_files[i])\n",
    "        high_path = os.path.join(freq_dir, high_files[i])\n",
    "\n",
    "        # Load LR\n",
    "        lr_img = np.array(Image.open(low_path).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "        lr_tensor = torch.tensor(lr_img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            pred = model(lr_tensor).cpu().numpy()\n",
    "\n",
    "        # remove batch and channel dims, scale to 0-255\n",
    "        pred_img = np.squeeze(pred)\n",
    "        pred_img = (pred_img * 255.0).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        # increase contrast (normalize like GT)\n",
    "        pred_img = cv2.normalize(pred_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        # save prediction\n",
    "        pred_path = os.path.join(pred_dir, f\"pred_{i+1}.png\")\n",
    "        Image.fromarray(pred_img).save(pred_path)\n",
    "\n",
    "        # Load GT\n",
    "        gt_img = cv2.imread(high_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if pred_img.shape != gt_img.shape:\n",
    "            pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "        # Metrics\n",
    "        psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "        ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "    # Results\n",
    "    if psnr_values and ssim_values:\n",
    "        print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "        print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n",
    "    else:\n",
    "        print(\"[Error] No valid pairs processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266d7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 650 → pred → compare with 1083 ----\n",
      "SSIM: avg=0.9553, min=0.9332, max=0.9669\n",
      "PSNR: avg=34.14 dB, min=33.13 dB, max=34.64 dB\n",
      "\n",
      "---- Stage 2: pred_1083 → pred → compare with 1800 ----\n",
      "SSIM: avg=0.9160, min=0.8855, max=0.9361\n",
      "PSNR: avg=30.38 dB, min=29.86 dB, max=31.15 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\clean_validation dataset\\png_images_650M_1083M_1800M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\clean_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"650_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1083_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1800_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 650 → pred → compare with 1083 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1083 → pred → compare with 1800 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09dce8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Stage 1: 900 → pred → compare with 1500 ----\n",
      "SSIM: avg=0.7507, min=0.5975, max=0.8729\n",
      "PSNR: avg=30.41 dB, min=29.70 dB, max=30.93 dB\n",
      "\n",
      "---- Stage 2: pred_1500 → pred → compare with 2500 ----\n",
      "SSIM: avg=0.7277, min=0.6192, max=0.8184\n",
      "PSNR: avg=28.53 dB, min=26.91 dB, max=31.14 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATASET_DIR = r\"C:\\Preet\\clean_validation dataset\\png_images_900M_1500M_2500M\"\n",
    "MODEL_PATH = r\"C:\\Preet\\clean_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "def run_model(img, model):\n",
    "    tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor).cpu().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    return cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# =========================\n",
    "# LOAD MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# =========================\n",
    "# INFERENCE 2-STAGE\n",
    "# =========================\n",
    "files_650 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"900_bscan.png\")])\n",
    "files_1083 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"1500_bscan.png\")])\n",
    "files_1800 = numerical_sort([f for f in os.listdir(DATASET_DIR) if f.endswith(\"2500_bscan.png\")])\n",
    "\n",
    "psnr_stage1, ssim_stage1 = [], []\n",
    "psnr_stage2, ssim_stage2 = [], []\n",
    "\n",
    "pred_dir1 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage1\")\n",
    "pred_dir2 = os.path.join(DATASET_DIR, \"predictions_unet3_simpleAG_stage2\")\n",
    "os.makedirs(pred_dir1, exist_ok=True)\n",
    "os.makedirs(pred_dir2, exist_ok=True)\n",
    "\n",
    "for i in range(len(files_650)):\n",
    "    # ---- Stage 1: 650 -> pred -> compare with 1083 ----\n",
    "    lr_img = np.array(Image.open(os.path.join(DATASET_DIR, files_650[i])).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    gt_1083 = cv2.imread(os.path.join(DATASET_DIR, files_1083[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083 = run_model(lr_img, model)\n",
    "    Image.fromarray(pred_1083).save(os.path.join(pred_dir1, f\"pred1_{i+1}.png\"))\n",
    "\n",
    "    if pred_1083.shape != gt_1083.shape:\n",
    "        pred_1083 = cv2.resize(pred_1083, (gt_1083.shape[1], gt_1083.shape[0]))\n",
    "\n",
    "    psnr_stage1.append(calculate_psnr(pred_1083, gt_1083))\n",
    "    ssim_stage1.append(calculate_ssim(pred_1083, gt_1083))\n",
    "\n",
    "    # ---- Stage 2: pred_1083 -> pred -> compare with 1800 ----\n",
    "    gt_1800 = cv2.imread(os.path.join(DATASET_DIR, files_1800[i]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    pred_1083_resized = cv2.resize(pred_1083, IMAGE_SIZE).astype(np.float32) / 255.0\n",
    "    pred_1800 = run_model(pred_1083_resized, model)\n",
    "    Image.fromarray(pred_1800).save(os.path.join(pred_dir2, f\"pred2_{i+1}.png\"))\n",
    "\n",
    "    if pred_1800.shape != gt_1800.shape:\n",
    "        pred_1800 = cv2.resize(pred_1800, (gt_1800.shape[1], gt_1800.shape[0]))\n",
    "\n",
    "    psnr_stage2.append(calculate_psnr(pred_1800, gt_1800))\n",
    "    ssim_stage2.append(calculate_ssim(pred_1800, gt_1800))\n",
    "\n",
    "# =========================\n",
    "# RESULTS\n",
    "# =========================\n",
    "print(\"\\n---- Stage 1: 900 → pred → compare with 1500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage1):.4f}, min={np.min(ssim_stage1):.4f}, max={np.max(ssim_stage1):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage1):.2f} dB, min={np.min(psnr_stage1):.2f} dB, max={np.max(psnr_stage1):.2f} dB\")\n",
    "\n",
    "print(\"\\n---- Stage 2: pred_1500 → pred → compare with 2500 ----\")\n",
    "print(f\"SSIM: avg={np.mean(ssim_stage2):.4f}, min={np.min(ssim_stage2):.4f}, max={np.max(ssim_stage2):.4f}\")\n",
    "print(f\"PSNR: avg={np.mean(psnr_stage2):.2f} dB, min={np.min(psnr_stage2):.2f} dB, max={np.max(psnr_stage2):.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6331e6",
   "metadata": {},
   "source": [
    "-- FOR TEWSTTING 400mHZ on trained 750Mhz model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cd345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Evaluating C:\\Preet\\400_670_Dataset ----\n",
      "SSIM: avg=0.7521, min=0.6279, max=0.8199\n",
      "PSNR: avg=29.71 dB, min=29.17 dB, max=30.27 dB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from math import log10\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "MODEL_PATH = r\"C:\\Preet\\clean_paired_bscans\\best_unet3_simpleAG.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1)\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, g):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.psi(g1 + x1)\n",
    "        return x * psi\n",
    "\n",
    "# ==========================\n",
    "# SIMPLE 3-LAYER UNET WITH ATTENTION\n",
    "# ==========================\n",
    "class UNet3SimpleWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ConvBlock(1, 64); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(64, 128); self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(128, 256); self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck: just a ConvBlock\n",
    "        self.bottleneck = ConvBlock(256, 512)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)\n",
    "        self.dec3 = ConvBlock(512 + 256, 256)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)\n",
    "        self.dec2 = ConvBlock(256 + 128, 128)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)\n",
    "        self.dec1 = ConvBlock(128 + 64, 64)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c1 = self.enc1(x); p1 = self.pool1(c1)\n",
    "        c2 = self.enc2(p1); p2 = self.pool2(c2)\n",
    "        c3 = self.enc3(p2); p3 = self.pool3(c3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Attention\n",
    "        u3 = self.up3(b); a3 = self.att3(c3, u3); d3 = self.dec3(torch.cat([u3, a3], dim=1))\n",
    "        u2 = self.up2(d3); a2 = self.att2(c2, u2); d2 = self.dec2(torch.cat([u2, a2], dim=1))\n",
    "        u1 = self.up1(d2); a1 = self.att1(c1, u1); d1 = self.dec1(torch.cat([u1, a1], dim=1))\n",
    "\n",
    "        return self.out_conv(d1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0: return float('inf')\n",
    "    return 20 * log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=255)\n",
    "\n",
    "def numerical_sort(files):\n",
    "    return sorted(files, key=lambda f: int(re.search(r'\\d+', f).group()))\n",
    "\n",
    "# =========================\n",
    "# LOAD SIMPLE UNET MODEL\n",
    "# =========================\n",
    "model = UNet3SimpleWithAttention().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n---- Evaluating {TEST_DIR} ----\")\n",
    "pred_dir = os.path.join(TEST_DIR, \"predictions_AG_unet\")\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "low_files = numerical_sort([f for f in os.listdir(TEST_DIR) if f.endswith(\"_l.png\")])\n",
    "high_files = numerical_sort([f for f in os.listdir(TEST_DIR) if f.endswith(\"_h.png\")])\n",
    "\n",
    "psnr_values, ssim_values = [], []\n",
    "\n",
    "for i in range(len(low_files)):\n",
    "    low_path = os.path.join(TEST_DIR, low_files[i])\n",
    "    high_path = os.path.join(TEST_DIR, high_files[i])\n",
    "\n",
    "    # Load LR\n",
    "    lr_img = np.array(Image.open(low_path).resize(IMAGE_SIZE), dtype=np.float32) / 255.0\n",
    "    lr_tensor = torch.tensor(lr_img).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        pred = model(lr_tensor).cpu().squeeze().numpy()\n",
    "\n",
    "    # Scale to 0–255\n",
    "    pred_img = (np.clip(pred, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
    "    pred_path = os.path.join(pred_dir, f\"pred_{i+1}.png\")\n",
    "    Image.fromarray(pred_img).save(pred_path)\n",
    "\n",
    "    # Load GT\n",
    "    gt_img = cv2.imread(high_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if pred_img.shape != gt_img.shape:\n",
    "        pred_img = cv2.resize(pred_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "    # Metrics\n",
    "    psnr_values.append(calculate_psnr(pred_img, gt_img))\n",
    "    ssim_values.append(calculate_ssim(pred_img, gt_img))\n",
    "\n",
    "if psnr_values and ssim_values:\n",
    "    print(f\"SSIM: avg={np.mean(ssim_values):.4f}, min={np.min(ssim_values):.4f}, max={np.max(ssim_values):.4f}\")\n",
    "    print(f\"PSNR: avg={np.mean(psnr_values):.2f} dB, min={np.min(psnr_values):.2f} dB, max={np.max(psnr_values):.2f} dB\")\n",
    "else:\n",
    "    print(\"[Error] No valid *_l.png and *_h.png pairs found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
